{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset collected is related to 17 campaigns that occurred between May 2008 and November 2010, corresponding to a total of 79354 contacts. During these phone campaigns, an attractive long-term deposit application, with good interest rates, was offered. For each contact, a large number of attributes was stored and if there was a success (the target variable). There were 6499 successes (8% success rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "Bank_marketing_campaigns_df = pd.read_csv('data/bank-additional-full.csv', sep = ';')\n",
    "\n",
    "Bank_marketing_campaigns_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Bank_marketing_campaigns_df.isnull().sum())\n",
    "print(Bank_marketing_campaigns_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To meet the business objective of improving marketing campaign efficiency and maintaining a similar number of successful outcomes with fewer contacts, the following tasks should be carried out:\n",
    "\n",
    "1. Clean and preprocess the data to handle missing values, inconsistencies, and categorical variables.\n",
    "2. Perform feature engineering and selection to identify the most relevant features for modeling.\n",
    "3. Split the data into training and testing sets to evaluate model performance on unseen data.\n",
    "4. Select and train appropriate classification models, such as logistic regression, decision trees, or support vector machines.\n",
    "5. Optimize model hyperparameters using techniques like cross-validation, grid search, or randomized search.\n",
    "6. Evaluate and compare model performance using relevant metrics to select the best model(s) for deployment.\n",
    "7. Interpret the selected model(s) to understand important features and refine marketing strategies.\n",
    "8. Deploy the model(s) in a production environment to support decision-making and optimize marketing campaigns.\n",
    "9. Monitor and maintain the deployed model(s) to ensure continued performance in line with business objectives.\n",
    "\n",
    "By performing these tasks, you can work towards enhancing the efficiency of marketing campaigns and achieving a similar number of successful customer subscriptions with reduced contact efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features (columns 1 - 7), prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Perform statistical tests to determine the association between each categorical feature and the target variable. I haved used the Chi-squared test to assess the independence between a categorical feature and the target variable. A low p-value from the Chi-squared test suggests that the categorical feature and the target variable are dependent, which could make the feature useful for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
      "job - p-value: 4.189763287563623e-199\n",
      "marital - p-value: 2.068014648442211e-26\n",
      "education - p-value: 3.3051890144025054e-38\n",
      "default - p-value: 5.161957951391637e-89\n",
      "housing - p-value: 0.05829447669453452\n",
      "loan - p-value: 0.5786752870441754\n",
      "contact - p-value: 1.525985652312996e-189\n",
      "month - p-value: 0.0\n",
      "day_of_week - p-value: 2.958482005278532e-05\n",
      "poutcome - p-value: 0.0\n",
      "y - p-value: 0.0\n",
      "Selected Categorical features: ['housing', 'loan']\n",
      "Based on data we will drop features: ['housing', 'loan'] that has no relevnes due to soce grter or equil than 0.05\n"
     ]
    }
   ],
   "source": [
    "Bank_marketing_campaigns_df = Bank_marketing_campaigns_df.convert_dtypes()\n",
    "categorical_features = list(Bank_marketing_campaigns_df.select_dtypes(include=['string']).columns)\n",
    "\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "\n",
    "rel_feature_list = []\n",
    "for feature in categorical_features:\n",
    "    contingency_table = pd.crosstab(Bank_marketing_campaigns_df[feature], Bank_marketing_campaigns_df['y'])\n",
    "    chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "    rel_feature_list += [feature] if p >= 0.05 else []\n",
    "    print(f\"{feature} - p-value: {p}\")\n",
    "print(\"Selected Categorical features:\", rel_feature_list)\n",
    "print(f\"Based on data we will drop features: {rel_feature_list} that has no relevnes due to soce grter or equil than 0.05\")\n",
    "\n",
    "Bank_marketing_campaigns_df.drop(rel_feature_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['age', 'job', 'marital', 'education', 'default', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n"
     ]
    }
   ],
   "source": [
    "df = Bank_marketing_campaigns_df\n",
    "categorical_features = list(Bank_marketing_campaigns_df.columns)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "# for feature in categorical_features:\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     sns.countplot(data=df, x=feature, hue='y')\n",
    "#     plt.title(f'{feature} vs Target= Yes/No')\n",
    "#     plt.show()\n",
    "#     print(\"Selected feature name:\", feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the visualization of relationships between each feature and the target variable, the plots reveal that the following columns may not have a significant effect on the machine learning model:\n",
    "day_of_week and pdays,\n",
    "\n",
    "we will drop them to increase processing te performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['job', 'marital', 'education', 'default', 'contact', 'month', 'poutcome', 'y']\n"
     ]
    }
   ],
   "source": [
    "Bank_marketing_campaigns_df.drop(['pdays','day_of_week'], axis=1, inplace=True)\n",
    "categorical_features = list(Bank_marketing_campaigns_df.select_dtypes(include=['string']).columns)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature_1 in categorical_features:\n",
    "#     for feature_2 in categorical_features:\n",
    "#         if feature_1 != feature_2:\n",
    "#             # Create a crosstab of the two categorical features\n",
    "#             crosstab = pd.crosstab(Bank_marketing_campaigns_df[feature_1], Bank_marketing_campaigns_df[feature_2])\n",
    "\n",
    "#             # Normalize crosstab to show proportions\n",
    "#             crosstab_norm = crosstab / crosstab.sum().sum()\n",
    "\n",
    "#             # Create a heatmap\n",
    "#             plt.figure(figsize=(10, 5))\n",
    "#             sns.heatmap(crosstab_norm, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "#             plt.xlabel(feature_2)\n",
    "#             plt.ylabel(feature_1)\n",
    "#             plt.title(f\"{feature_1} vs {feature_2}\")\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           feature  importance\n",
      "7         duration    0.352399\n",
      "14       euribor3m    0.129655\n",
      "0              age    0.108013\n",
      "15     nr.employed    0.066190\n",
      "1              job    0.053399\n",
      "3        education    0.047910\n",
      "8         campaign    0.047306\n",
      "10        poutcome    0.043721\n",
      "13   cons.conf.idx    0.027684\n",
      "2          marital    0.026226\n",
      "12  cons.price.idx    0.022145\n",
      "11    emp.var.rate    0.021645\n",
      "6            month    0.018425\n",
      "9         previous    0.014889\n",
      "5          contact    0.010533\n",
      "4          default    0.009860\n"
     ]
    }
   ],
   "source": [
    "df = Bank_marketing_campaigns_df\n",
    "# Encode categorical features using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "data_encoded = df.copy()\n",
    "for feature in categorical_features:\n",
    "    data_encoded[feature] = le.fit_transform(df[feature])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_encoded.drop('y', axis=1)\n",
    "y = data_encoded['y']\n",
    "\n",
    "# Train a random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Display feature importances\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': clf.feature_importances_})\n",
    "importances = importances.sort_values('importance', ascending=False)\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_encoded.drop('y', axis=1)\n",
    "y = data_encoded['y']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize or normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Majority Class Classifier  where customer will not excpet the offer is): 0.8876\n",
      "Baseline Accuracy (Minority Class Classifier  where customer will  excpet the offer is): 0.1124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# value_counts = y_train.value_counts()\n",
    "# print((100*value_counts[1])/(value_counts[0]+ value_counts[1])  )\n",
    "# print((100*value_counts[0])/(value_counts[0]+ value_counts[1])  )\n",
    "\n",
    "# Determine the majority class in the training dataset\n",
    "majority_class = y_train.value_counts().idxmax()\n",
    "\n",
    "# Predict the majority class for all samples in the test dataset\n",
    "y_pred_baseline = [majority_class] * len(y_test)\n",
    "\n",
    "# Calculate the accuracy of the baseline classifier\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"Baseline Accuracy (Majority Class Classifier  where customer will not excpet the offer is): {baseline_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Baseline Accuracy (Minority Class Classifier  where customer will  excpet the offer is): {1 - baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our test data \n",
    "Baseline Accuracy (Majority Class Classifier  where customer will not excpet the offer is): 0.8876\n",
    "Baseline Accuracy (Minority Class Classifier  where customer will  excpet the offer is): 0.1124\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred = logistic_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9102\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10968\n",
      "           1       0.67      0.40      0.50      1389\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.80      0.69      0.73     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10690   278]\n",
      " [  832   557]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, zero_division=1)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of our logistic_regression model?\n",
    "\n",
    "The accuracy of a model is a performance metric that measures the proportion of correct predictions made by the model out of the total number of predictions. In other words, it is the ratio of the number of correct predictions to the total number of predictions made. Accuracy is commonly used to evaluate the performance of classification models.\n",
    "\n",
    "Accuracy: 0.9102\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.97      0.95     10968\n",
    "           1       0.67      0.40      0.50      1389\n",
    "\n",
    "    accuracy                           0.91     12357\n",
    "   macro avg       0.80      0.69      0.73     12357\n",
    "weighted avg       0.90      0.91      0.90     12357\n",
    "\n",
    "Confusion Matrix:\n",
    "[[10690   278] [  832   557]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", logistic_regression),\n",
    "    (\"KNN\", knn),\n",
    "    (\"Decision Tree\", decision_tree),\n",
    "    (\"SVM\", svm),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    Train_Time = time.time() - start_time\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    results.append((name, Train_Time, accuracy, train_accuracy,test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Time  Accuracy  Train Accuracy  Test Accuracy\n",
      "3                  SVM    6.009472  0.911791        0.918248       0.911791\n",
      "0  Logistic Regression    0.038035  0.910172        0.909091       0.910172\n",
      "1                  KNN    0.002002  0.900461        0.930041       0.900461\n",
      "2        Decision Tree    0.104095  0.887675        1.000000       0.887675\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Model\",\"Train Time\",\"Accuracy\",\"Train Accuracy\",\"Test Accuracy\"])\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 31),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 11),\n",
    "    'min_samples_split': range(2, 21),\n",
    "    'min_samples_leaf': range(1, 21)\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", logistic_regression, logistic_regression_params),\n",
    "    (\"KNN\", knn, knn_params),\n",
    "    (\"Decision Tree\", decision_tree, decision_tree_params),\n",
    "    (\"SVM\", svm, svm_params),\n",
    "]\n",
    "\n",
    "# models1 = [\n",
    "#     (\"Logistic Regression\", logistic_regression, logistic_regression_params),\n",
    "#     (\"KNN\", knn, knn_params),\n",
    "#     (\"Decision Tree\", decision_tree, decision_tree_params),\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparams, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 7\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      8\u001b[0m Train_Time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m     10\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1388\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_results = []\n",
    "\n",
    "for name, model, params in models:\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    Train_Time = time.time() - start_time\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    tuned_results.append((name, Train_Time, best_params, best_score))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Logistic Regression', 8.709679365158081, {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}, 0.9093337582033627), ('KNN', 80.67747116088867, {'metric': 'euclidean', 'n_neighbors': 30, 'weights': 'distance'}, 0.9071139927371524), ('Decision Tree', 150.16674828529358, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 4}, 0.9139123342283633), ('SVM', 674.1086885929108, {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, 0.9093339867574555)]\n",
      "                 Model  Tranning time  \\\n",
      "0  Logistic Regression       8.709679   \n",
      "1                  KNN      80.677471   \n",
      "2        Decision Tree     150.166748   \n",
      "3                  SVM     674.108689   \n",
      "\n",
      "                                     Best_Parameters  Best Score  \n",
      "0  {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...    0.909334  \n",
      "1  {'metric': 'euclidean', 'n_neighbors': 30, 'we...    0.907114  \n",
      "2  {'criterion': 'gini', 'max_depth': 5, 'min_sam...    0.913912  \n",
      "3       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}    0.909334  \n",
      "0    {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...\n",
      "1    {'metric': 'euclidean', 'n_neighbors': 30, 'we...\n",
      "2    {'criterion': 'gini', 'max_depth': 5, 'min_sam...\n",
      "3         {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Name: Best_Parameters, dtype: string\n"
     ]
    }
   ],
   "source": [
    "print(tuned_results)\n",
    "tuned_results_df = pd.DataFrame(tuned_results, columns=[\"Model\", \"Tranning time\", \"Best_Parameters\", \"Best Score\"])\n",
    "tuned_results_df = tuned_results_df.astype({'Best_Parameters':'string'})\n",
    "print(tuned_results_df)\n",
    "\n",
    "print(tuned_results_df.Best_Parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "     \n",
    "}\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': range(1, 31),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "    \n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 11),\n",
    "    'min_samples_split': range(2, 21),\n",
    "    'min_samples_leaf': range(1, 21)\n",
    "    \n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m models \u001b[39m=\u001b[39m [\n\u001b[1;32m----> 2\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mLogistic Regression\u001b[39m\u001b[39m\"\u001b[39m, logistic_regression, logistic_regression_params),\n\u001b[0;32m      3\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mKNN\u001b[39m\u001b[39m\"\u001b[39m, knn, knn_params),\n\u001b[0;32m      4\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mDecision Tree\u001b[39m\u001b[39m\"\u001b[39m, decision_tree, decision_tree_params),\n\u001b[0;32m      5\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mSVM\u001b[39m\u001b[39m\"\u001b[39m, svm, svm_params),\n\u001b[0;32m      6\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logistic_regression' is not defined"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", logistic_regression, logistic_regression_params),\n",
    "    (\"KNN\", knn, knn_params),\n",
    "    (\"Decision Tree\", decision_tree, decision_tree_params),\n",
    "    (\"SVM\", svm, svm_params),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m n_iter_pram \u001b[39m=\u001b[39m [\u001b[39m12\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m16\u001b[39m]\n\u001b[0;32m      4\u001b[0m Index  \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m name, model, params \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(n_iter_pram[Index])\n\u001b[0;32m      9\u001b[0m     randomized_search \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_distributions\u001b[39m=\u001b[39mparams, n_iter \u001b[39m=\u001b[39m n_iter_pram[Index], cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "tuned_results_randomized = []\n",
    "\n",
    "n_iter_pram = [12,50,50,16]\n",
    "Index  = 0\n",
    "\n",
    "for name, model, params in models:\n",
    "    \n",
    "    print(n_iter_pram[Index])\n",
    "    randomized_search = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter = n_iter_pram[Index], cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "    Index = Index + 1\n",
    "    start_time = time.time()\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    Train_Time = time.time() - start_time\n",
    "    \n",
    "\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = randomized_search.best_score_\n",
    "  \n",
    "    tuned_results_randomized.append((name,Train_Time, best_params, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Logistic Regression', 8.38815689086914, {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.1}, 0.9092990721124853), ('KNN', 9.78328275680542, {'weights': 'distance', 'n_neighbors': 28, 'metric': 'euclidean'}, 0.9068018479921613), ('Decision Tree', 1.5548157691955566, {'min_samples_split': 15, 'min_samples_leaf': 9, 'max_depth': 5, 'criterion': 'gini'}, 0.9137735898648529), ('SVM', 682.5839326381683, {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}, 0.9093339867574555)]\n",
      "[('Logistic Regression', 7.954242944717407, {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}, 0.9092990721124853), ('KNN', 81.06671690940857, {'metric': 'euclidean', 'n_neighbors': 30, 'weights': 'distance'}, 0.9071139927371524), ('Decision Tree', 154.0595941543579, {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}, 0.9139123342283633), ('SVM', 688.9562339782715, {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, 0.9093339867574555)]\n",
      "                 Model  Train_Time  \\\n",
      "0  Logistic Regression    8.388157   \n",
      "1                  KNN    9.783283   \n",
      "2        Decision Tree    1.554816   \n",
      "3                  SVM  682.583933   \n",
      "\n",
      "                                     Best Parameters  Best Score  \n",
      "0  {'solver': 'liblinear', 'penalty': 'l1', 'C': ...    0.909299  \n",
      "1  {'weights': 'distance', 'n_neighbors': 28, 'me...    0.906802  \n",
      "2  {'min_samples_split': 15, 'min_samples_leaf': ...    0.913774  \n",
      "3       {'kernel': 'rbf', 'gamma': 'scale', 'C': 10}    0.909334  \n"
     ]
    }
   ],
   "source": [
    "print(tuned_results_randomized)\n",
    "print(tuned_results)\n",
    "\n",
    "tuned_results_randomized_df = pd.DataFrame(tuned_results_randomized, columns=[\"Model\", \"Train_Time\",\"Best Parameters\", \"Best Score\"])\n",
    "print(tuned_results_randomized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMC_test_df =  pd.read_csv('data/bank-additional.csv', sep = ';')\n",
    "# BMC_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMC_test_df = BMC_test_df.convert_dtypes()\n",
    "# categorical_features = list(BMC_test_df.select_dtypes(include=['string']).columns)\n",
    "\n",
    "# print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "\n",
    "# rel_feature_list = []\n",
    "# for feature in categorical_features:\n",
    "#     contingency_table = pd.crosstab(BMC_test_df[feature], BMC_test_df['y'])\n",
    "#     chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "#     rel_feature_list += [feature] if p >= 0.05 else []\n",
    "#     #print(f\"{feature} - p-value: {p}\")\n",
    "\n",
    "# #print(\"Selected Categorical features:\", rel_feature_list)\n",
    "# print(f\"Based on data we will drop features: {rel_feature_list} that has no relevnes due to soce grter or equil than 0.05\")\n",
    "\n",
    "# BMC_test_df.drop(rel_feature_list, axis=1, inplace=True)\n",
    "# BMC_test_df.drop(['pdays'], axis=1, inplace=True)\n",
    "# categorical_features = list(BMC_test_df.select_dtypes(include=['string']).columns)\n",
    "# print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a function that implements the selected model and returns the target value\n",
    "\n",
    "1. Train the chosen model with the optimal hyperparameters on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SomeModel(**best_params)\n",
    "best_model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
